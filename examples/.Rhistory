# save output in a PDF
rmarkdown::render(
input = "nlsy_diffs.R",
output_format = "pdf_document",
output_file = "ssa_names_trends_log"
)
# save output in a PDF
rmarkdown::render(
input = "ssa_names_trends.R",
output_format = "pdf_document",
output_file = "ssa_names_trends_log"
)
install.packages('rmarkdown')
rmarkdown::render(
input = "ssa_names_trends.R",
output_format = "pdf_document",
output_file = "ssa_names_trends_log"
)
# save output in a PDF
rmarkdown::render(
input = "ssa_names_trends.R",
output_format = "pdf_document",
output_file = "ssa_names_trends_log"
)
# input Stata file (need haven library for importing Stata file)
library(haven)
# uncomment if these packages are not installed
# install.packages(c('tidyverse','haven'))
# analyzes naming trends in the social security names database (national).
# takes interest in frequency of hilary/hillary before and after clinton elections.
# input Stata file (need haven library for importing Stata file)
library(haven)
ssa <- read_dta("https://github.com/tvogl/econ121/raw/main/data/ssa_names.dta")
# summarize
summary(ssa)
# data structure (need tidyverse library for the glimpse function)
library(tidyverse)
glimpse(ssa)
# keep only girl names, and only Hilary and Hillary
df <- ssa[which(ssa$sex=="F" & ssa$name %in% c("Hilary", "Hillary")), ]
# summarize and glimpse new data frame
summary(df)
glimpse(df)
# graph counts of both names, with a vertical line at 1992, 2008, and 2016
# we will use the ggplot2 package, which is already loaded in the tideverse
ggplot(df, aes(x=year, y=freq, group=name, color=name)) +
geom_line() +
geom_vline(xintercept=c(1992, 2008, 2016))
library(haven)
ssa <- read_dta("https://github.com/tvogl/econ121/raw/main/data/ssa_names.dta")
summary(ssa)
library(tidyverse)
ssa.alltime <- ssa %>%
group_by(name, sex) %>%
summarise(total_freq = sum(freq))
glimpse(ssa.alltime)
ssa.alltime <- ssa %>%
group_by(name, sex) %>%
summarise(total_freq = sum(freq))
glimpse(ssa.alltime)
ssa.alltime <- ssa %>%
group_by(name, sex) %>%
summarise(total.freq = sum(freq)) %>%
sort(total.freq)
ssa.alltime <- ssa %>%
group_by(name, sex) %>%
summarise(total.freq = sum(freq))
ssa.alltime <- ssa.alltime %>% sort(total.freq)
ssa.alltime <- ssa.alltime %>% arrange(total.freq)
glimpse(ssa.alltime)
ssa.alltime <- ssa.alltime[order(-total.freq_,]
ssa.alltime <- ssa.alltime[order(-total.freq),]
ssa.alltime <- ssa.alltime[order(-ssa.alltime$total.freq),]
glimpse(ssa.alltime)
ssa.alltime[c(1:10),]
ssa %>%
subset((name=="James"&sex=="M")|(name=="Mary"&sex=="F")) %>%
group_by(name) %>%
summarise(mean_freq = mean(freq))
ssa %>%
subset((name=="James"&sex=="M")|(name=="Mary"&sex=="F")|
(name=="Hilary"&sex=="F")|(name=="Hillary"&sex=="F")) %>%
group_by(name) %>%
summarise(total.freq = sum(freq))
ggplot(ssa %>% subset((name=="Hilary"&sex=="F")|(name=="Hillary"&sex=="F")), aes(x=year, y=freq, group=name, color=name)) +
geom_line() +
geom_vline(xintercept=c(1992, 2008, 2016))
# This example studies the relationship between low birth weight and test scores
# uncomment to install plm package, which contains panel data models
# install.packages("plm")
# Import dataset
library(haven)
nlsy <- read_dta("https://github.com/tvogl/econ121/raw/main/data/nlsy_deming.dta")
# Decribe the data. Test scores go from 0 to 100, with a mean in the 40s.
summary(nlsy)
# Birth weight is in logs, which is a little complicated to interpret
# Let's convert to ounces
nlsy$bw <- exp(nlsy$lnbw)
#Have a look at the summary statistics
summary(nlsy$bw)
nlsy$bw_bin <- floor(nlsy$bw/10)*10
table(nlsy$bw_bin)
nlsy$bw_bin <- case_when(bw_bin<70 ~ 70,                  # compress the long tails into big bins
bw_bin>=70 & bw_bin<140 ~ bw_bin,
bw_bin>=140 ~ 140)
library(dplyr) # for case_when() and group_by()
nlsy$bw_bin <- case_when(bw_bin<70 ~ 70,                  # compress the long tails into big bins
bw_bin>=70 & bw_bin<140 ~ bw_bin,
bw_bin>=140 ~ 140)
nlsy$bw_bin <- 70 * ifelse(bw_bin<70,1,0) +  # compress the long tails into big bins
bw_bin * ifelse(bw_bin>=70 & bw_bin<140,1,0) +
140 * ifelse(bw_bin>=140,1,0)
nlsy$bw_bin <- 70 * ifelse(nlsy$bw_bin<70,1,0) +  # compress the long tails into big bins
nlsy$bw_bin * ifelse(nlsy$bw_bin>=70 & nlsy$bw_bin<140,1,0) +
140 * ifelse(nlsy$bw_bin>=140,1,0)
tabls(nlsy$bw_bin)
table(nlsy$bw_bin)
library(dplyr) # for if_else() and group_by()
nlsy$bw_bin <- floor(nlsy$bw/10)*10               # now 100 means "100-109.9" and so forth
nlsy$bw_bin <- 70 * ifelse(nlsy$bw_bin<70,1,0) +  # compress the long tails into big bins
nlsy$bw_bin * ifelse(nlsy$bw_bin>=70 & nlsy$bw_bin<140,1,0) +
140 * ifelse(nlsy$bw_bin>=140,1,0)
nlsy_bins1 <- nlsy %>% group_by(bw_bin) %>% summarise(mean_test = mean(comp_score_11to14))
library(ggplot2) # for plot
ggplot(nlsy_bins1,aes(x=bw_bin,y=mean_test)) +
geom_line()
View(nlsy_bins1)
library(dplyr) # for if_else() and group_by()
nlsy$bw_bin <- floor(nlsy$bw/10)*10               # now 100 means "100-109.9" and so forth
nlsy$bw_bin <- 70 * ifelse(nlsy$bw_bin<70,1,0) +  # compress the long tails into big bins
nlsy$bw_bin * ifelse(nlsy$bw_bin>=70 & nlsy$bw_bin<140,1,0) +
140 * ifelse(nlsy$bw_bin>=140,1,0)
nlsy_bins1 <- nlsy %>% group_by(bw_bin) %>% summarise(mean_test = mean(comp_score_11to14,na.rm = TRUE))
library(ggplot2) # for plot
ggplot(nlsy_bins1,aes(x=bw_bin,y=mean_test)) +
geom_line()
ggplot(nlsy_bins1,aes(x=bw_bin,y=mean_test)) +
geom_line() +
geom_point()
nlsy$momedlevel <- case_when(nlsy$momed<12 ~ "<HS",
nlsy$momed==12 ~ "HS",
nlsy$momed>12 ~ ">HS")
table(nlsy$momedlevel)
nlsy_bins2 <- nlsy %>% group_by(bw_bin, momedlevel) %>% summarise(mean_test = mean(comp_score_11to14,na.rm = TRUE))
View(nlsy_bins2)
ggplot(nlsy_bins2,aes(x=bw_bin,y=mean_test,color=momedlevel)) +
geom_line() +
geom_point()
ggplot(nlsy_bins2,aes(x=bw_bin,y=mean_test,color=momedlevel,na.rm=TRUE)) +
geom_line() +
geom_point()
nlsy_bins2 <- nlsy %>%
filter(!is.na(momedlevel)) %>%  # remove obs with missing maternal education
group_by(bw_bin, momedlevel) %>%
summarise(mean_test = mean(comp_score_11to14,na.rm = TRUE))
ggplot(nlsy_bins2,aes(x=bw_bin,y=mean_test,color=momedlevel)) +
geom_line() +
geom_point()
nlsy$vlow_bw <- ifelse(bw<53,1,0)
nlsy$vlow_bw <- ifelse(nlsy$bw<53,1,0)
View(nlsy)
ggplot(data=nlsy, mapping=aes(x=vlow_bw, y=comp_score_11to14)) +
stat_summary(fun.data=mean_sdl, geom="bar")
# This example studies the relationship between low birth weight and test scores
# uncomment to install plm package, which contains panel data models
# install.packages("plm")
# Import dataset
library(haven)
nlsy <- read_dta("https://github.com/tvogl/econ121/raw/main/data/nlsy_deming.dta")
# Decribe the data. Test scores go from 0 to 100, with a mean in the 40s.
summary(nlsy)
# Birth weight is in logs, which is a little complicated to interpret
# Let's convert to ounces
nlsy$bw <- exp(nlsy$lnbw)
# Have a look at the summary statistics
summary(nlsy$bw)
# Let's give ourselves a sense of how birth weight relates to the
# composite test score by plotting mean test scores by birthweight.
# I create a binned version of birthweight to make the plot less noisy.
library(dplyr) # for if_else() and group_by()
nlsy$bw_bin <- floor(nlsy$bw/10)*10               # now 100 means "100-109.9" and so forth
nlsy$bw_bin <- 70 * ifelse(nlsy$bw_bin<70,1,0) +  # compress the long tails into big bins
nlsy$bw_bin * ifelse(nlsy$bw_bin>=70 & nlsy$bw_bin<140,1,0) +
140 * ifelse(nlsy$bw_bin>=140,1,0)
nlsy_bins1 <- nlsy %>%
group_by(bw_bin) %>%
summarise(mean_test = mean(comp_score_11to14,na.rm = TRUE))
library(ggplot2) # for plot
ggplot(nlsy_bins1,aes(x=bw_bin,y=mean_test)) +
geom_line() +
geom_point()
# There is a strong relationship! But how much of this is
# due to family characteristics? Let's generate separate
# plots for mothers with <12, 12, and >12 years of schooling.
nlsy$momedlevel <- case_when(nlsy$momed<12 ~ "<HS",
nlsy$momed==12 ~ "HS",
nlsy$momed>12 ~ ">HS")
nlsy_bins2 <- nlsy %>%
filter(!is.na(momedlevel)) %>%  # remove obs with missing maternal education
group_by(bw_bin, momedlevel) %>%
summarise(mean_test = mean(comp_score_11to14,na.rm = TRUE))
ggplot(nlsy_bins2,aes(x=bw_bin,y=mean_test,color=momedlevel)) +
geom_line() +
geom_point()
# Maternal education is clearly associated with test scores. At the same time,
# these plots don't look that much flatter than the full sample plot above.
# How much of the relationship is attributable to maternal characteristics
# rather than child health per se? We need to use fixed effects to find out.
# For simplicity, let's generate a very low birth weight indicator,
# based on the 53 ounce threshold.
nlsy$vlow_bw <- ifelse(nlsy$bw<53,1,0)
# For this binary categorization, a bar graph may be a convenient way
# to visualize the data.
ggplot(data=nlsy, mapping=aes(x=vlow_bw, y=comp_score_11to14)) +
stat_summary(fun.data=mean_sdl, geom="bar")
# Let's look at the structure of the panel data for a few key variables
nlsy <- nlsy[order(mom_id),] # sort by mom_id so siblings are next to each other
glimpse(nlsy)
# OLS with robust standard errors
library(estimatr) # for lm_robust()
lm_robust(comp_score_11to14 ~ vlow_bw,data = nlsy)
# OLS with clustered standard errors
lm_robust(comp_score_11to14 ~ vlow_bw,data = nlsy,clusters = mom_id)
# Random effects
# The estimated coefficient changes a lot,
# which suggest that the between-family variation
# and the within-family variation lead to different
# coefficients. Most researchers would conclude
# that we should rely on fixed effects.
library(plm) # for panel data models
re <- plm(comp_score_11to14 ~ vlow_bw, data = nlsy, index = c("mom_id"), model = "random")
summary(re)
# Random effects with cluster robust standard errors
# We need to pass our estimates through the coeftest() function from the lmtest package
library(lmtest)
coeftest(re, vcov=vcovHC(re, cluster="group"))
# Fixed effects
# Here, the estimated coefficient shrinks even more,
# consistent with upward bias from between-family variation.
fe <- plm(comp_score_11to14 ~ vlow_bw, data = nlsy, index = c("mom_id"), model = "within")
summary(fe)
summary(fe, vcov=vcovHC(model))
summary(fe, vcov=vcovHC(fe))
library(haven)
sb <- read_dta("https://github.com/tvogl/econ121/raw/main/data/SeatBelts.dta")
# Generate log income
sb$lnincome <- log(sb$income)
library(plm)
library(dplyr) # to generate lag
sb_mod <- sb %>% # create new data frame with lags, subsetted to have obs with lag = 0
group_by(fips) %>%
arrange(year) %>%
mutate(l.primary = lag(primary, n=1, default = NA),
l.secondary = lag(primary, n=1, default = NA)) %>%
filter(l.primary==0 & l.secondary==0)
View(sb_mod)
arrange(year)
sb_mod <- sb %>% # create new data frame with lags, subsetted to have obs with lag = 0
group_by(fips) %>%
mutate(l.primary = lag(primary, n=1, default = NA),
l.secondary = lag(primary, n=1, default = NA)) %>%
filter(l.primary==0 & l.secondary==0)
sb_mod <- sb %>% # create new data frame with lags, subsetted to have obs with lag = 0
arrange(year) %>%
group_by(fips) %>%
mutate(l.primary = lag(primary, n=1, default = NA),
l.secondary = lag(primary, n=1, default = NA)) %>%
filter(l.primary==0 & l.secondary==0)
View(sb_mod)
sb_mod <- sb %>% # create new data frame with lags, subsetted to have obs with lag = 0
arrange(fips, year) %>%
group_by(fips) %>%
mutate(l.primary = lag(primary, n=1, default = NA),
l.secondary = lag(primary, n=1, default = NA)) %>%
filter(l.primary==0 & l.secondary==0)
View(sb_mod)
sb_mod <- sb %>% # create new data frame with lags, subsetted to have obs with lag = 0
arrange(fips, year) %>%
group_by(fips) %>%
mutate(l.primary = lag(primary, n=1, default = NA),
l.secondary = lag(secondary, n=1, default = NA)) %>%
filter(l.primary==0 & l.secondary==0)
View(sb_mod)
fd_mod <- plm(fatalityrate ~ primary + secondary + year.f, data = sb_mod,
index = c("fips","year"), model = "fd")
summary(fd_mod,vcov=vcovHC(fd)) # heteroskedasticity- and cluster- robust
sb$year.f <- factor(sb$year) # factor variable version of year, for inclusion as covariate
fd_mod <- plm(fatalityrate ~ primary + secondary + year.f, data = sb_mod,
index = c("fips","year"), model = "fd")
summary(fd_mod,vcov=vcovHC(fd)) # heteroskedasticity- and cluster- robust
sb$year.f <- factor(sb$year) # factor variable version of year, for inclusion as covariate
sb_mod <- sb %>% # create new data frame with lags, subsetted to have obs with lag = 0
arrange(fips, year) %>%
group_by(fips) %>%
mutate(l.primary = lag(primary, n=1, default = NA),
l.secondary = lag(secondary, n=1, default = NA)) %>%
filter(l.primary==0 & l.secondary==0)
fd_mod <- plm(fatalityrate ~ primary + secondary + year.f, data = sb_mod,
index = c("fips","year"), model = "fd")
summary(fd_mod,vcov=vcovHC(fd)) # heteroskedasticity- and cluster- robust
summary(fd_mod,vcov=vcovHC(fd_mod)) # heteroskedasticity- and cluster- robust
fd <- plm(fatalityrate ~ primary + secondary + year.f, data = sb,
index = c("fips","year"), model = "fd")
summary(fd,vcov=vcovHC(fd, method="white1")) # heteroskedasticity-robust, not cluster-robust
summary(fd,vcov=vcovHC(fd)) # heteroskedasticity- and cluster- robust
sb_mod <- sb %>% # create new data frame with lags, subsetted to have obs with lag = 0
arrange(fips, year) %>%
group_by(fips) %>%
mutate(l.primary = lag(primary, n=1, default = NA),
l.secondary = lag(secondary, n=1, default = NA)) %>%
filter(l.primary==0 & l.secondary==0)
fd_mod <- plm(fatalityrate ~ primary + secondary + year.f, data = sb_mod,
index = c("fips","year"), model = "fd")
summary(fd_mod,vcov=vcovHC(fd_mod)) # heteroskedasticity- and cluster- robust
sb_mod <- sb %>% # create new data frame with lags, subsetted to have obs with lag = 0
arrange(fips, year) %>%
group_by(fips) %>%
mutate(l.primary = lag(primary, n=1, default = NA),
l.secondary = lag(secondary, n=1, default = NA))
fd_mod <- plm(fatalityrate ~ primary + secondary + year.f, data = sb_mod,
index = c("fips","year"), model = "fd")
summary(fd_mod,vcov=vcovHC(fd_mod)) # h
fd_mod <- plm(fatalityrate ~ primary + secondary + year.f,
data = filter(sb_mod,l.primary==0 & l.secondary==0,
index = c("fips","year"), model = "fd")
summary(fd_mod,vcov=vc
fd_mod <- plm(fatalityrate ~ primary + secondary + year.f,
data = filter(sb_mod,l.primary==0 & l.secondary==0,
index = c("fips","year"), model = "fd")
summary(fd_mod,vcov=vcovHC(fd_mod)) # heteroskedasticity- and cluster- robust
fd_mod <- plm(fatalityrate ~ primary + secondary + year.f,
data = filter(sb_mod,l.primary==0 & l.secondary==0),
index = c("fips","year"), model = "fd")
summary(fd_mod,vcov=vcovHC(fd_mod)) # heteroskedasticity- and cluster- robust
summary(sb_mod$l.primary)
summary(sb_mod$l.secondary)
sb_mod <- sb %>% # create new data frame with lags, subsetted to have obs with lag = 0
arrange(fips, year) %>%
group_by(fips) %>%
mutate(l.primary = lag(primary, n=1, default = NA),
l.secondary = lag(secondary, n=1, default = NA)) %>%
filter(l.primary==0 & l.secondary==0)
fd_mod <- plm(fatalityrate ~ primary + secondary + year.f, data = sb_mod,
index = c("fips","year"), model = "fd")
summary(fd_mod)
twfe <- plm(fatalityrate ~ primary + secondary, data = sb,
index = c("fips","year"), model = "within", effect = "twoways")
summary(twfe,vcov=vcovHC(twfe, method="white1")) # heteroskedasticity-robust, not cluster-robust
fd <- plm(fatalityrate ~ primary + secondary + year.f, data = sb,
index = c("fips","year"), model = "fd")
summary(fd,vcov=vcovHC(fd, method="white1")) # heteroskedasticity-robust, not cluster-robust
summary(sb_mod)
plm(fatalityrate ~ primary + secondary + year.f, data = sb_mod, index = c("fips","year"), model = "fd")
fd_mod <- plm(fatalityrate ~ primary + secondary + factor(year), data = sb_mod,
index = c("fips","year"), model = "fd")
summary(fd_mod,vcov=vcovHC(fd_mod)) # heteroskedasticity- and cluster- robust
# drop uncontested elections
library(dplyr)
# this R script estimates the political party incumbency
# advantage in US House elections
library(haven)
elections <- read_dta("https://github.com/tvogl/econ121/raw/main/data/elections.dta")
# this R script estimates the political party incumbency
# advantage in US House elections
library(haven)
elections <- read_dta("https://github.com/tvogl/econ121/raw/main/data/elections.dta")
# this R script estimates the political party incumbency
# advantage in US House elections
library(haven)
elections <- read_dta("https://github.com/tvogl/econ121/raw/main/data/elections.dta")
# the running variable in this RD analysis is the
# democratic vote margin of victory: the vote share
# of the democrat minus the vote share of the other
# top-two candidate. the democrat wins for all values
# greater than zero
# the dependent variable is the democratic vote share
# in the next election
# we also have two predetermined variables: the
# democratic vote share in the previous election and
# the democrat's years of political experience
summary(elections)
# histogram of the democratic vote margin of victory
# we make sure that the bars don't overlap zero
library(ggplot2)
ggplot(elections, aes(x=difdemshare)) +
geom_histogram(binwidth=0.025, boundary=-1, alpha=.7)
# drop uncontested elections
library(dplyr)
elections <- elections %>% filter(abs(difdemshare)!=1)
# now generate a binning variable for the figures
# each bin will be 0.05 wide
elections <- mutate(elections, bin = floor(difdemshare*20)/20+0.025)
prop.table(table(elections$bin))
# now generate local means for each of the bins
local_means <- elections %>%
group_by(bin) %>%
summarise_at(vars(demsharenext, demshareprev, demofficeexp), list(mean))
# now let's run our main RD, using a global 4th order polynomial
# to approximate the conditional expectation function. we allow
# the shape of the polynomial to be different above and below
# the victory threshold. following david lee, we will cluster
# by district-year
library(estimatr)
poly <- lm_robust(demsharenext ~ right + difdemshare + difdemshare2 + difdemshare3 + difdemshare4
+ rdifdemshare + rdifdemshare2 + rdifdemshare3 + rdifdemshare4,
data = elections, cluster=statedisdec)
summary(poly)
# so a democratic victory now causes a 7 point increase in
# the next election's democratic vote share
# let's generate a predicted value
elections$demsharenext_hat_poly <- predict(poly, elections)
# let's check whether this result is robust to including the
# predetermined variables as controls
poly_control <- lm_robust(demsharenext ~ right + difdemshare + difdemshare2 + difdemshare3 + difdemshare4
+ rdifdemshare + rdifdemshare2 + rdifdemshare3 + rdifdemshare4
+ demshareprev + demofficeexp,
data = elections, cluster=statedisdec)
summary(poly_control)
# doesn't seem to matter much, which is promising
# let's generate a predicted value, holding
# demshareprev demofficeexp at their means
demshareprev.mean <- mean(elections$demshareprev)
demofficeexp.mean <- mean(elections$demofficeexp)
elections_temp <- mutate(elections,demshareprev = demshareprev.mean,
demofficeexp = demofficeexp.mean)
elections$demsharenext_hat_poly_control <- predict(poly_control, elections_temp)
rm(elections_temp, demshareprev.mean, demofficeexp.mean)
# the above result suggests that demshareprev demofficeexp
# don't change discontinuously at zero, but we can also check
# directly
lm_robust(demshareprev ~ right + difdemshare + difdemshare2 + difdemshare3 + difdemshare4
+ rdifdemshare + rdifdemshare2 + rdifdemshare3 + rdifdemshare4,
data = elections, cluster=statedisdec)
lm_robust(demofficeexp ~ right + difdemshare + difdemshare2 + difdemshare3 + difdemshare4
+ rdifdemshare + rdifdemshare2 + rdifdemshare3 + rdifdemshare4,
data = elections, cluster=statedisdec)
# the global polynomial might be misleading, let's check for
# local mean differences and also run a local linear regression
# we use a bandwidth of 0.1
lmean <- lm_robust(demsharenext ~ right,
data = elections, subset = abs(difdemshare)<0.1, cluster=statedisdec)
summary(lmean)
lpoly <- lm_robust(demsharenext ~ right + difdemshare + rdifdemshare,
data = elections, subset = abs(difdemshare)<0.1, cluster=statedisdec)
summary(lpoly)
# let's generate a predicted value
elections$demsharenext_hat_lpoly <- predict(lpoly, elections)
# let's plot the data and our various predictions
# add a local linear regression over all the data
ggplot(elections, aes(difdemshare, demsharenext)) +
geom_point(data = local_means, aes(bin, demsharenext)) +
geom_line(aes(difdemshare, demsharenext_hat_poly), color = "blue") +
geom_line(aes(difdemshare, demsharenext_hat_poly_control), color = "navy") +
geom_line(data = subset(elections,abs(difdemshare)<.1), aes(difdemshare, demsharenext_hat_lpoly), color = "tomato")
# let's also plot the local means for the predetermined variables
library(patchwork) # to combine ggplots
plot1 <- ggplot(local_means, aes(bin, demshareprev)) +
geom_point()
plot2 <- ggplot(local_means, aes(bin, demofficeexp)) +
geom_point()
plot1 + plot2
ggplot(elections, aes(difdemshare, demsharenext)) +
geom_point(data = local_means, aes(bin, demsharenext)) +
geom_line(aes(difdemshare, demsharenext_hat_poly), color = "blue") +
geom_line(aes(difdemshare, demsharenext_hat_poly_control), color = "navy") +
geom_line(data = subset(elections,abs(difdemshare)<.1), aes(difdemshare, demsharenext_hat_lpoly), color = "tomato")
